{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vdeOOX2Ol4dT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Using cached scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.5.4\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "!pip install scipy\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_59NgFjMoRpE"
   },
   "source": [
    "# Transfer Learning from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jhYlJ-iAoVZE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3.5%5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root = 'data', train = True, transform = ToTensor(), download = True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=100,shuffle=True,num_workers=4)\n",
    "    \n",
    "test_data = datasets.MNIST(root = 'data', train = False,transform = ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size=100,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 0.2001\n",
      "Epoch [1/10], Step [200/600], Loss: 0.0517\n",
      "Epoch [1/10], Step [300/600], Loss: 0.0540\n",
      "Epoch [1/10], Step [400/600], Loss: 0.0395\n",
      "Epoch [1/10], Step [500/600], Loss: 0.0515\n",
      "Epoch [1/10], Step [600/600], Loss: 0.0348\n",
      "Epoch [2/10], Step [100/600], Loss: 0.0959\n",
      "Epoch [2/10], Step [200/600], Loss: 0.0951\n",
      "Epoch [2/10], Step [300/600], Loss: 0.0879\n",
      "Epoch [2/10], Step [400/600], Loss: 0.0399\n",
      "Epoch [2/10], Step [500/600], Loss: 0.1312\n",
      "Epoch [2/10], Step [600/600], Loss: 0.0584\n",
      "Epoch [3/10], Step [100/600], Loss: 0.0249\n",
      "Epoch [3/10], Step [200/600], Loss: 0.0156\n",
      "Epoch [3/10], Step [300/600], Loss: 0.0096\n",
      "Epoch [3/10], Step [400/600], Loss: 0.0132\n",
      "Epoch [3/10], Step [500/600], Loss: 0.0665\n",
      "Epoch [3/10], Step [600/600], Loss: 0.0283\n",
      "Epoch [4/10], Step [100/600], Loss: 0.0429\n",
      "Epoch [4/10], Step [200/600], Loss: 0.0625\n",
      "Epoch [4/10], Step [300/600], Loss: 0.0104\n",
      "Epoch [4/10], Step [400/600], Loss: 0.0457\n",
      "Epoch [4/10], Step [500/600], Loss: 0.0108\n",
      "Epoch [4/10], Step [600/600], Loss: 0.0010\n",
      "Epoch [5/10], Step [100/600], Loss: 0.0417\n",
      "Epoch [5/10], Step [200/600], Loss: 0.0121\n",
      "Epoch [5/10], Step [300/600], Loss: 0.0715\n",
      "Epoch [5/10], Step [400/600], Loss: 0.0950\n",
      "Epoch [5/10], Step [500/600], Loss: 0.2189\n",
      "Epoch [5/10], Step [600/600], Loss: 0.0491\n",
      "Epoch [6/10], Step [100/600], Loss: 0.0403\n",
      "Epoch [6/10], Step [200/600], Loss: 0.0243\n",
      "Epoch [6/10], Step [300/600], Loss: 0.0100\n",
      "Epoch [6/10], Step [400/600], Loss: 0.0178\n",
      "Epoch [6/10], Step [500/600], Loss: 0.0495\n",
      "Epoch [6/10], Step [600/600], Loss: 0.0613\n",
      "Epoch [7/10], Step [100/600], Loss: 0.0976\n",
      "Epoch [7/10], Step [200/600], Loss: 0.1184\n",
      "Epoch [7/10], Step [300/600], Loss: 0.0168\n",
      "Epoch [7/10], Step [400/600], Loss: 0.0265\n",
      "Epoch [7/10], Step [500/600], Loss: 0.0140\n",
      "Epoch [7/10], Step [600/600], Loss: 0.0061\n",
      "Epoch [8/10], Step [100/600], Loss: 0.0222\n",
      "Epoch [8/10], Step [200/600], Loss: 0.0980\n",
      "Epoch [8/10], Step [300/600], Loss: 0.0500\n",
      "Epoch [8/10], Step [400/600], Loss: 0.0288\n",
      "Epoch [8/10], Step [500/600], Loss: 0.0571\n",
      "Epoch [8/10], Step [600/600], Loss: 0.0026\n",
      "Epoch [9/10], Step [100/600], Loss: 0.0026\n",
      "Epoch [9/10], Step [200/600], Loss: 0.0275\n",
      "Epoch [9/10], Step [300/600], Loss: 0.0748\n",
      "Epoch [9/10], Step [400/600], Loss: 0.0755\n",
      "Epoch [9/10], Step [500/600], Loss: 0.0054\n",
      "Epoch [9/10], Step [600/600], Loss: 0.0037\n",
      "Epoch [10/10], Step [100/600], Loss: 0.0092\n",
      "Epoch [10/10], Step [200/600], Loss: 0.0149\n",
      "Epoch [10/10], Step [300/600], Loss: 0.1218\n",
      "Epoch [10/10], Step [400/600], Loss: 0.0930\n",
      "Epoch [10/10], Step [500/600], Loss: 0.0042\n",
      "Epoch [10/10], Step [600/600], Loss: 0.1262\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "num_epochs = 10\n",
    "        \n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "\n",
    "        output = cnn(images)[0]               \n",
    "        loss = loss_func(output, labels)\n",
    "            \n",
    "        # clear gradients for this training step   \n",
    "        optimizer.zero_grad()           \n",
    "\n",
    "        # backpropagation, compute gradients \n",
    "        loss.backward()    \n",
    "        # apply gradients             \n",
    "        optimizer.step()                \n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 0.98\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            pass\n",
    "print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "svhn_transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "    transforms.CenterCrop(28),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "svhn_data = datasets.SVHN(root = 'data', split = 'test',transform = svhn_transform, download = True)\n",
    "svhn_loader = torch.utils.data.DataLoader(svhn_data,batch_size=100,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 0.22\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in svhn_loader:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            pass\n",
    "print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "D7047E Assignment 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
